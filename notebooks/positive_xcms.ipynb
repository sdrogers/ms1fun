{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positive mode voting with the direct xcms output\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "base_dir = '/Users/simon/git/ms1fun/'\n",
    "sys.path.append(base_dir + 'code')\n",
    "sys.path.append(base_dir + 'dbs')\n",
    "\n",
    "from corr_cluster import Peak,BetaLike,CorrCluster\n",
    "from formula import Formula\n",
    "import pylab as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "prefix = '/Users/simon/Dropbox/BioResearch/Meta_clustering/ms1fundata/Beer/PositiveMode/Beer3Full/xcms/'\n",
    "filename = 'Beer_3_Full1'\n",
    "files.append((prefix,filename,False))\n",
    "\n",
    "prefix = '/Users/simon/Dropbox/BioResearch/Meta_clustering/ms1fundata/urine/pos/xcms/'\n",
    "filename = 'Urine_37_fullscan1_POS'\n",
    "files.append((prefix,filename,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87 transformations\n"
     ]
    }
   ],
   "source": [
    "import transformation\n",
    "transformations = transformation.load_from_file(base_dir + 'dbs/pos_transformations_reduced.yml')\n",
    "print \"Loaded \" + str(len(transformations)) + \" transformations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running file Beer_3_Full1\n",
      "Loaded 8394 peaks\n",
      "Greedy clustering done, resulting in 439 clusters\n",
      "Running file Urine_37_fullscan1_POS\n",
      "Loaded 8388 peaks\n",
      "Greedy clustering done, resulting in 473 clusters\n"
     ]
    }
   ],
   "source": [
    "bl = BetaLike()\n",
    "clusterings = {}\n",
    "for f in files:\n",
    "\n",
    "    filename = f[1]\n",
    "    prefix = f[0]\n",
    "    print \"Running file \" + filename\n",
    "    csvfile = prefix + filename + '.xcms.csv'\n",
    "    coc = CorrCluster(bl,csvfile,greedy_thresh=0.7,correct=f[2],file_type='xcms.csv',rt_thresh=2)\n",
    "    clusterings[filename] = coc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing voting on file Beer_3_Full1\n",
      "Performing voting on file Urine_37_fullscan1_POS\n"
     ]
    }
   ],
   "source": [
    "from voter import Voter,PeakGroup\n",
    "groups = {}\n",
    "for f in files:\n",
    "    v = Voter(transformations)\n",
    "    filename = f[1]\n",
    "    print \"Performing voting on file {}\".format(filename)\n",
    "    file_groups = []\n",
    "    for cluster in clusterings[filename].clusters:\n",
    "        file_groups += v.make_groups(cluster.members)\n",
    "    groups[filename] = file_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from databases import Standards\n",
    "st = Standards()\n",
    "all_hits = {}\n",
    "for f in files:\n",
    "    filename = f[1]\n",
    "    all_hits[filename] = st.get_group_hits(groups[filename],use_max_vote = True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the groups according to votes (top ones first)\n",
    "global_adduct_counts = {}\n",
    "global_fragment_counts = {}\n",
    "global_transformation_counts = {}\n",
    "for f in files:\n",
    "    filename = f[1]\n",
    "    outpre = 'xcms_output/pos/' + filename\n",
    "\n",
    "    temp_groups = sorted(groups[filename],key = lambda x:x.vote,reverse=True)\n",
    "    outfile = outpre + '_by_vote.txt'\n",
    "    \n",
    "\n",
    "    with open(outfile,'w') as f:\n",
    "        for i,group in enumerate(temp_groups):\n",
    "            line = \"vote: {}, M: {}\\n\".format(group.vote,group.M)\n",
    "            f.write(line)\n",
    "            head_line = '\\tPeak m/z,Peak rt,Peak intensity,transformation (transformed mass,vote)\\n'\n",
    "            f.write(head_line)\n",
    "            for (peak,transformation,transmass) in sorted(group.members,key = lambda x: x[1].vote,reverse=True):\n",
    "                line = \"\\t{:.4f},{:.4f},{:.2e},{} ({:.4f},{})\\n\".format(peak.mass,peak.rt,peak.intensity,transformation,transmass,transformation.vote)\n",
    "                f.write(line)\n",
    "            f.write('\\n')\n",
    "            \n",
    "    temp_groups = sorted(groups[filename],key = lambda x:x.M)\n",
    "    outfile = outpre + '_by_M.txt'\n",
    "    \n",
    "    with open(outfile,'w') as f:\n",
    "        for i,group in enumerate(temp_groups):\n",
    "            line = \"vote: {}, M: {}\\n\".format(group.vote,group.M)\n",
    "            f.write(line)\n",
    "            head_line = '\\tPeak m/z,Peak rt,Peak intensity,transformation (transformed mass,vote)\\n'\n",
    "            f.write(head_line)\n",
    "            for (peak,transformation,transmass) in sorted(group.members,key = lambda x: x[1].vote,reverse=True):\n",
    "                line = \"\\t{:.4f},{:.4f},{:.2e},{} ({:.4f},{})\\n\".format(peak.mass,peak.rt,peak.intensity,transformation,transmass,transformation.vote)\n",
    "                f.write(line)\n",
    "            f.write('\\n')\n",
    "\n",
    "    with open(outpre + '_matched_std.txt','w') as f:\n",
    "        for mol in all_hits[filename]:\n",
    "            group = all_hits[filename][mol]\n",
    "            line = \"{} (vote={})\\n\".format(mol,group.vote)\n",
    "            f.write(line)\n",
    "            head_line = '\\tPeak m/z,Peak rt,Peak intensity,transformation (transformed mass,vote)\\n'\n",
    "            f.write(head_line)\n",
    "            for (peak,transformation,transmass) in sorted(group.members,key = lambda x: x[1].vote,reverse=True):\n",
    "                line = \"\\t{:.4f},{:.4f},{:.2e},{} ({:.4f},{})\\n\".format(peak.mass,peak.rt,peak.intensity,transformation,transmass,transformation.vote)\n",
    "                f.write(line)\n",
    "            f.write('\\n')\n",
    "\n",
    "\n",
    "    include_singletons = False\n",
    "    trans_counts = {}\n",
    "    tot = 0\n",
    "    for tr in transformations:\n",
    "        trans_counts[tr] = 0\n",
    "    for group in groups[filename]:\n",
    "        if not include_singletons:\n",
    "            if len(group.members) == 1:\n",
    "                continue\n",
    "        for p,t,_ in group.members:\n",
    "            trans_counts[t] += 1\n",
    "            tot += 1\n",
    "\n",
    "    with open(outpre + '_tran_counts.txt','w') as f:\n",
    "        for tr in sorted(transformations,key = lambda x: x.vote, reverse=True):\n",
    "            line = \"{},{},{:.4f}\\n\".format(tr,trans_counts[tr],trans_counts[tr]/(1.0*tot))\n",
    "            f.write(line)\n",
    "\n",
    "    # output the counts of particular adducts / fragments\n",
    "    frag_counts = {}\n",
    "    adduct_counts = {}\n",
    "    adduct_tot = 0\n",
    "    frag_tot = 0\n",
    "    for tr in transformations:\n",
    "        for f in tr.fragments:\n",
    "            if not f in frag_counts:\n",
    "                frag_counts[f] = 0\n",
    "        for a in tr.adducts:\n",
    "            if not a in adduct_counts:\n",
    "                adduct_counts[a] = 0\n",
    "                \n",
    "    for group in groups[filename]:\n",
    "        for p,t,_ in group.members:\n",
    "            for f in t.fragments:\n",
    "                frag_counts[f] += 1\n",
    "                frag_tot += 1\n",
    "            for a in t.adducts:\n",
    "                adduct_counts[a] += 1\n",
    "                adduct_tot += 1\n",
    "                \n",
    "    with open(outpre + '_adduct_counts.txt','w') as f:\n",
    "        for a in adduct_counts:\n",
    "            line = \"{},{},{:.4f}\\n\".format(a,adduct_counts[a],adduct_counts[a]/(1.0*adduct_tot))\n",
    "            f.write(line)\n",
    "    \n",
    "    with open(outpre + '_fragment_counts.txt','w') as f:\n",
    "        for fr in frag_counts:\n",
    "            line = \"{},{},{:.4f}\\n\".format(fr,frag_counts[fr],frag_counts[fr]/(1.0*frag_tot))\n",
    "            f.write(line)\n",
    "    \n",
    "    global_adduct_counts[filename] = adduct_counts\n",
    "    global_fragment_counts[filename] = frag_counts\n",
    "    global_transformation_counts[filename] = trans_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
